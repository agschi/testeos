<properties
   pageTitle="Lista de comprobación de escalabilidad | Microsoft Azure"
   description="Guía de la lista de comprobación de escalabilidad sobre cuestiones de diseño para el escalado automático de Azure."
   services=""
   documentationCenter="na"
   authors="dragon119"
   manager="masimms"
   editor=""
   tags=""/>

<tags
   ms.service="best-practice"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="12/16/2015"
   ms.author="masashin"/>

# Lista de comprobación de escalabilidad

![](media/best-practices-scalability-checklist/pnp-logo.png)

## Diseño de servicios
- **Crear particiones de la carga de trabajo**. Diseñe las partes del proceso para que sean discretas y puedan descomponerse, y minimice el tamaño de cada parte mientras sigue las reglas típicas de separación de problemas y el principio de responsabilidad única. Esto permite que las partes del componente se distribuyan de manera que se maximiza el uso de cada unidad de proceso (por ejemplo, un servidor de bases de datos o de roles) y se facilita el escalado de la aplicación agregando instancias adicionales de recursos específicos. Para obtener más información, consulte [Compute Partitioning Guidance](https://msdn.microsoft.com/library/dn568099.aspx) (Guía de creación de particiones de procesos).
- **Diseñar para escalar**. El escalado permite a las aplicaciones reaccionar a una carga variable aumentando y disminuyendo el número de instancias de roles, colas y otros servicios que usan. No obstante, la aplicación debe diseñarse teniendo en cuenta esto. Por ejemplo, la aplicación y los servicios que utiliza no deben tener estado para que las solicitudes se enruten a cualquier instancia y que la incorporación o eliminación de instancias específicas no afecte negativamente a los usuarios actuales. También es necesario implementar la configuración o detección automática de instancias cuando se agregan y se quitan de forma que el código de la aplicación pueda realizar el enrutamiento necesario. Por ejemplo, una aplicación web puede utilizar un conjunto de colas con un enfoque round-robin para enrutar las solicitudes a los servicios de fondo que se ejecutan en roles de trabajador. La aplicación web debe ser capaz de detectar cambios en el número de colas para enrutar las solicitudes y equilibrar correctamente la carga de la aplicación.
- **Escalar como unidad**. Tenga en cuenta la incorporación de recursos adicionales que se adapten al crecimiento. Para cada recurso, debe conocer los límites de escalado superiores y utilizar el particionamiento o la descomposición para ir más allá de estos límites. Determine las unidades de escala para el sistema en términos de conjuntos de recursos bien definidos. Esto facilita la aplicación de operaciones de escalado horizontal y tiende a evitar los impactos negativos en la aplicación debidos a las limitaciones impuestas por la falta de recursos en alguna parte del sistema global. Por ejemplo, agregar un número x de roles de web y de trabajador puede requerir un número y de colas adicionales y un número z de cuentas de almacenamiento para controlar la carga de trabajo adicional generada por los roles, por lo que una unidad de escala podría consistir en x roles de web y de trabajo, _y_ colas y _z_ cuentas de almacenamiento. Diseñe la aplicación para que se escale fácilmente mediante la incorporación de una o más unidades de escala.
- **Evitar afinidad del cliente**. Siempre que sea posible, asegúrese de que la aplicación no requiere afinidad para que las solicitudes se puedan enrutar a cualquier instancia y el número de instancias sea irrelevante. Esto también evita la sobrecarga de tener que almacenar, recuperar y mantener la información de estado para cada usuario.
- **Aprovechar las características de escalado automático de la plataforma**. Cuando la plataforma de hospedaje sea compatible con una capacidad de escalado automático, como el escalado automático de Azure, es preferible su uso al de mecanismos de terceros o personalizados a menos que el mecanismo integrado no pueda cumplir los requisitos. Use reglas de escalado programadas siempre que sea posible para garantizar que los recursos estén disponibles sin retrasos iniciales, pero agregue escalado automático reactivo a las reglas cuando sea apropiado para hacer frente a cambios inesperados en la demanda. Puede utilizar las operaciones de escalado automático de la API de administración de servicios para ajustar el escalado automático y agregar contadores personalizados a las reglas, más allá de las opciones de configuración disponibles en el portal web. Para obtener más información, consulte la página [Auto-scaling guidance](best-practices-auto-scaling.md) (Guía de escalado automático).
- **Descargar tareas de uso intensivo de CPU y E/S como tareas en segundo plano**. Si se espera que una solicitud a un servicio tarde mucho tiempo en ejecutarse o absorbe recursos considerables, descargue el procesamiento para esta solicitud a una tarea independiente. Utilice roles de trabajo o trabajos en segundo plano (en función de la plataforma de hospedaje) para ejecutar estas tareas. Esta estrategia permite que el servicio continúe recibiendo más solicitudes y siga respondiendo. Para obtener más información, consulte [Background jobs guidance](best-practices-background-jobs.md) (Guía de trabajos en segundo plano).
- **Distribuir la carga de trabajo para tareas en segundo plano**. Donde haya muchas tareas en segundo plano, o las tareas requieran mucho tiempo o recursos, distribuya el trabajo en varias unidades de proceso (por ejemplo, roles de trabajo o trabajos en segundo plano). El [Patrón de consumidores en competencia](https://msdn.microsoft.com/library/dn568101.aspx) proporciona una posible solución.
- **Considerar la posibilidad de moverse hacia una arquitectura que _no comparte nada_**. Una arquitectura que no comparte nada utiliza nodos autosuficientes e independientes que no tienen ningún punto de contención, como servicios o almacenamiento compartidos. En teoría, este sistema puede escalarse casi indefinidamente. Mientras un enfoque de no compartir nada no suele ser práctico por lo general para la mayoría de las aplicaciones, puede proporcionar oportunidades de diseño para una mejor escalabilidad. Por ejemplo, evitar el uso del estado de sesión del servidor, la afinidad del cliente y las particiones de datos constituyen buenos ejemplos de cómo moverse hacia un arquitectura que no comparte nada.

## Administración de datos

- **Usar particiones de datos** Divida los datos entre varias bases de datos y servidores de bases de datos o diseñe la aplicación para que utilice servicios de almacenamiento de datos que puedan proporcionar estas particiones de forma transparente (entre los ejemplos se incluyen Escalado elástico de Base de datos SQL de Azure y almacenamiento de tablas de Azure). Este enfoque puede ayudar a maximizar el rendimiento y permitir un escalado más fácil. Existen diferentes técnicas de creación de particiones como la partición horizontal, vertical y funcional: puede utilizar una combinación de ellas para aprovechar al máximo el rendimiento mejorado de consultas, simplificar la escalabilidad, flexibilizar la administración, mejorar la disponibilidad y hacer coincidir el tipo de almacén con los datos que va a contener. Además, considere la posibilidad de utilizar distintos tipos de almacén de datos para tipos de datos diferentes, eligiendo los tipos en función de si están optimizados para el tipo de datos específico. Esto puede incluir el uso de almacenamiento de tablas, una base de datos de documento o un almacén de datos column-family en lugar de o como una base de datos relacional. Para obtener más información, consulte [Data partitioning guidance](best-practices-data-partitioning.md) (Guía de creación de particiones de datos).
- **Diseñar para coherencia final** La coherencia final mejora la escalabilidad al reducir o suprimir el tiempo necesario para sincronizar los datos relacionados con particiones en varios almacenes. La desventaja es que los datos no son siempre coherentes cuando se leen y algunas operaciones de escritura pueden provocar conflictos. La coherencia final es perfecta para situaciones en las que se leen con frecuencia los mismos datos pero no se suelen escribir tan a menudo. Para obtener más información, consulte [Data consistency guidance](#insertlink#) (Guía de coherencia de datos).
- **Reducir interacciones fragmentadas entre componentes y servicios**. Evite diseñar interfaces _fragmentadas_ para servicios, en las que una aplicación debe realizar varias llamadas a un servicio (cada una de las cuales devuelve una pequeña cantidad de datos) en lugar de una única llamada que puede devolver todos los datos. Siempre que sea posible, combine varias operaciones relacionadas en una única solicitud cuando la llamada se realiza a un servicio o componente que tiene una latencia apreciable. Esto hace que resulte más fácil supervisar el rendimiento y optimizar operaciones complejas. Por ejemplo, use procedimientos almacenados en bases de datos para encapsular una lógica compleja, y reducir el número de recorridos de ida y vuelta y el bloqueo de recursos. 
- **Usar colas para equilibrar la carga de escrituras de datos de alta velocidad**. Los incrementos en la demanda de un servicio pueden saturarlo y provocar errores cada vez mayores. Para evitar esto, considere la posibilidad de implementar el [Patrón de equilibrio de carga basado en colas](https://msdn.microsoft.com/library/dn589783.aspx). Utilice una cola que actúa como búfer entre una tarea y un servicio que invoca para equilibrar cargas pesadas intermitentes que, de lo contrario, pueden provocar errores en el servicio o la interrupción de la tarea.
- **Minimizar la carga en el almacén de datos**. El almacén de datos es por lo general un cuello de botella en el procesamiento, un recurso costoso que no suele resultar fácil de escalar horizontalmente. Siempre que sea posible, quite lógica (por ejemplo, para procesar documentos XML u objetos JSON) del almacén de datos y realice el procesamiento dentro de la aplicación. Por ejemplo, en lugar de pasar XML a la base de datos (que no sea como cadena opaca para el almacenamiento), serialice o deserialice el XML dentro de la capa de aplicación y páselo de forma nativa el almacén de datos. Suele ser mucho más fácil escalar horizontalmente la aplicación que el almacén de datos, por lo que debe intentar hacer gran parte del procesamiento de proceso intensivo dentro de la aplicación.
- **Minimizar el volumen de datos recuperados**. Recupere solo los datos que necesita especificando las columnas y utilizando criterios para seleccionar las filas. Utilice parámetros de valores de tabla y el nivel de aislamiento adecuado. Use mecanismos como ETags para evitar tener que recuperar datos innecesariamente.
- **Utilizar la caché de forma agresiva**. Utilice el almacenamiento en caché siempre que sea posible para reducir la carga de los recursos y servicios que generan o proporcionan datos. El almacenamiento en caché normalmente es adecuado para datos que sean relativamente estáticos o cuya obtención requiera un procesamiento considerable. El almacenamiento en caché debe realizarse en todos los niveles donde sea adecuado en cada capa de la aplicación, incluido el acceso a datos y la generación de la interfaz de usuario. Para obtener más información, consulte [Caching Guidance](best-practices-caching.md) (Guía de almacenamiento en caché).
- **Controlar el crecimiento y la retención de datos**. La cantidad de datos almacenados por una aplicación crecerá con el tiempo. Este crecimiento aumentará los costos de almacenamiento e incrementará la latencia al obtener acceso a los datos, lo que afecta al rendimiento de la aplicación. Es posible archivar periódicamente algunos de los datos antiguos a los que ya no se tiene acceso o mover los datos a los que rara vez se tiene acceso a un almacén de larga duración que sea más económico, aunque la latencia de acceso sea mayor.
- **Optimizar DTO mediante un formato binario eficaz**. Los objetos de transferencia de datos se pasan entre las capas de una aplicación varias veces, por lo que minimizar el tamaño reducirá la carga en los recursos y la red. Sin embargo, equilibre el ahorro y la sobrecarga de conversión de datos al formato requerido en cada ubicación en la que se utilizan, y adopte un formato que tenga la máxima interoperabilidad para habilitar una fácil reutilización de un componente.
- **Establecer control de caché**. Diseñe y configure la aplicación para usar el almacenamiento en caché de salida o el almacenamiento en caché de fragmentos siempre que sea posible para minimizar la carga de procesamiento.
- **Habilitar el almacenamiento en caché del cliente**. Las aplicaciones web deben habilitar la configuración de la caché en el contenido que puede almacenarse en caché. Esto suele estar desactivado de forma predeterminada. Configure el servidor a fin de proporcionar los encabezados de control de caché adecuados para habilitar el almacenamiento en caché de contenido en servidores proxy y clientes.
- **Usar almacenamiento de blobs de Azure y CDN para reducir la carga en la aplicación**. Considere la posibilidad de almacenar contenido público estático o relativamente estático como imágenes, recursos, scripts y hojas de estilos en el almacenamiento de blobs. Este enfoque libera la aplicación de la carga producida por la generación dinámica de este contenido para cada solicitud. Además, considere la posibilidad de usar el servicio CDN para almacenar en caché este contenido y ofrecérselo a los clientes. Con el servicio CDN puede mejorar el rendimiento en el cliente porque el contenido se proporciona desde el centro de datos geográficamente más cercano que contiene una memoria caché de CDN. Para obtener más información, vea la [Guía del servicio CDN](best-practices-cdn.md).

- **Optimizar y ajustar consultas SQL e índices**. Algunas instrucciones o construcciones de T-SQL pueden tener un impacto en el rendimiento, que se puede reducir al optimizar el código en un procedimiento almacenado. Por ejemplo, debe evitarse convertir tipos **datetime** en **varchar** antes de comparar con un valor literal **datetime**, en su lugar, use las funciones de comparación de fecha y hora. La falta de índices adecuados puede ralentizar la ejecución de la consulta. Si utiliza un marco de asignación relacional de objetos (ORM), entienda cómo funciona y cómo puede afectar al rendimiento de la capa de acceso a datos. Para obtener más información, consulte [Optimizar consultas](https://technet.microsoft.com/library/ms176005.aspx).
- **Considerar la posibilidad de desnormalizar datos**. La normalización de datos ayuda a evitar la duplicación y las incoherencias. Sin embargo, mantener varios índices, comprobar la integridad referencial, realizar varios accesos a fragmentos pequeños de datos y combinar tablas para volver a ensamblar los datos supone una sobrecarga que puede afectar al rendimiento. Piense si es aceptable tener un volumen de almacenamiento de información adicional y duplicación para reducir la carga en el almacén de datos. Además, tenga en cuenta si se puede confiar en la propia aplicación (que normalmente será más fácil de escalar) para realizar tareas como administración de la integridad referencial a fin de reducir la carga en el almacén de datos. Para obtener más información, consulte [Data partitioning guidance](https://github.com/mspnp/azure-guidance/blob/master/Data%20partitioning.md) (Guía de creación de particiones de datos).

## Implementación del servicio
- **Usar llamadas asincrónicas**. Siempre que sea posible, use código asincrónico al obtener acceso a recursos o servicios que pueden estar limitados por ancho de banda de E/S o de red, o que tienen una latencia apreciable, para evitar bloquear el subproceso que realiza la llamada. Utilice el patrón asincrónico basado en tareas para implementar operaciones asincrónicas. Para obtener más información, consulte la página [Modelo asincrónico basado en tareas (TAP)](https://msdn.microsoft.com/library/hh873175.aspx) en el sitio web de Microsoft.
- **Evitar bloquear recursos y utilizar en su lugar un enfoque optimista**. No bloquee nunca el acceso a recursos como almacenamiento u otros servicios que tienen una latencia apreciable, porque esto suele provocar un rendimiento deficiente. Utilice siempre enfoques optimistas para administrar operaciones simultáneas, como escribir en el almacenamiento, y use las características del almacenamiento para administrar conflictos. En aplicaciones distribuidas, los datos pueden ser solo coherentes en último lugar.
- **Comprimir datos altamente comprimibles a través de redes de alta latencia y ancho de banda bajo**. En la mayoría de los casos, en una aplicación web, el volumen mayor de datos generados por la aplicación y que se pasan a través de la red son respuestas HTTP a solicitudes de cliente. La compresión HTTP puede reducir esto considerablemente, en especial para el contenido estático. Esto puede ofrecer un ahorro de costos, así como reducir la carga en la red, aunque la compresión de contenido dinámico aplica una carga fraccionalmente mayor en el servidor. En otros entornos más generalizados, la compresión de datos puede reducir el volumen de datos que se transmiten y minimizar el tiempo y los costos de transferencia, pero los procesos de compresión y descompresión se verán sobrecargados. Por lo tanto, la compresión solo se debe usar cuando haya un aumento de rendimiento demostrable. Otros métodos de serialización, como la codificación JSON o binaria, pueden reducir el tamaño de carga a la vez que tienen menos impacto en el rendimiento, mientras que XML es probable que lo aumente.
- **Minimizar el tiempo que las conexiones y los recursos están en uso**. Mantenga los recursos y las conexiones solo si necesita utilizarlos. Por ejemplo, abra las conexiones lo más tarde posible y permita que se devuelven al grupo de conexiones en cuanto pueda. Adquiera recursos tan tarde como sea posible y deshágase de ellos tan pronto como sea posible.
- **Minimizar el número de conexiones necesarias**. Las conexiones de servicio absorben recursos. Siempre que sea posible, limite el número necesario y asegúrese de que se reutilizan las conexiones existentes. Por ejemplo, después de realizar la autenticación, utilice la suplantación cuando sea necesario para ejecutar código como identidad específica. Esto puede ayudar a hacer un mejor uso del grupo de conexiones gracias a su reutilización. 

	> [AZURE.NOTE]:** Las API para algunos servicios reutilizarán automáticamente las conexiones, siempre que se signa las directrices específicas para el servicio. Es importante comprender las condiciones que habilitan la reutilización de las conexiones para cada servicio que utiliza la aplicación.
- **Enviar solicitudes por lotes para optimizar el uso de red**. Por ejemplo, envíe y lea mensajes en lotes al tener acceso a una cola y realice varias lecturas o escrituras como lote si tiene acceso a un almacenamiento o a una memoria caché. Esto puede ayudar a maximizar la eficiencia de los servicios y almacenes de datos al reducir el número de llamadas a través de la red.
- **Evitar un requisito para almacenar el estado de la sesión del servidor** siempre que sea posible. La administración del estado de la sesión del servidor requiere normalmente la afinidad del cliente (enrutamiento de cada solicitud a la misma instancia de servidor), lo que afecta a la capacidad de escalado del sistema. Idealmente, debería diseñar clientes que no tengan estado con respecto a los servidores que utilizan. Sin embargo, si la aplicación debe mantener el estado de sesión, almacene datos confidenciales o grandes volúmenes de datos por cliente en una caché distribuida del servidor a la que puedan tener acceso todas las instancias de la aplicación.
- **Optimizar esquemas de almacenamiento de tablas**. Al utilizar almacenes de tablas como almacenamiento en tablas Azure que necesitan pasar y procesar nombres de tablas y columnas y con cada consulta, considere la posibilidad de utilizar nombres más cortos para reducir esta sobrecarga. No obstante, no sacrifique la legibilidad o la manejabilidad utilizando nombres compactos que no sean intuitivos.
- **Aprovechar TPL para realizar operaciones asincrónicas**. La biblioteca (TPL) facilita la escritura de código asincrónico que realiza operaciones dependientes de E/S. Use _ConfigureAwait (false)_ siempre que sea posible para eliminar la dependencia de una continuación sobre un contexto de sincronización específico y reducir las posibilidades de que se produzca un interbloqueo de subprocesos.
- **Crear dependencias de recursos durante la implementación o al iniciar la aplicación**. Evite llamadas repetidas a métodos que prueban la existencia de un recurso y luego lo crean si no existe (métodos como _CloudTable.CreateIfNotExists_ y _CloudQueue.CreateIfNotExists_ en la biblioteca de clientes de almacenamiento de Azure siguen este patrón). Estos métodos pueden suponer una sobrecarga considerable si se invocan antes de cada acceso a una tabla de almacenamiento o una cola de almacenamiento. En su lugar, cree los recursos necesarios al implementar la aplicación o al iniciarla por primera vez (es aceptable una única llamada a _CreateIfNotExists_ para cada recurso en el código de inicio para un rol web o de trabajo). Sin embargo, asegúrese de controlar las excepciones que pueden surgir si el código intenta obtener acceso a un recurso que no existe. En estas situaciones, debe registrar la excepción y posiblemente avisar a un operador de que falta un recurso. En algunas circunstancias, puede ser adecuado crear el recurso que falta como parte del código de control de excepción pero debe adoptar este enfoque con precaución ya que la inexistencia del recurso puede ser indicativa de un error de programación (un nombre de recurso mal escrito, por ejemplo) o algún otro problema de nivel de infraestructura.
- **Uso de marcos de trabajo ligeros**. Elija cuidadosamente las API y los marcos de trabajo que utiliza para minimizar el uso de recursos, el tiempo de ejecución y la carga general de la aplicación. Por ejemplo, el uso de Web API para controlar las solicitudes de servicio puede reducir la superficie de la aplicación y aumentar la velocidad de ejecución, pero es posible que no resulte adecuado para escenarios avanzados en los que se requieren capacidades de WCF adicionales.
- **Posibilidad de reducir el número de cuentas de servicio**. Por ejemplo, utilice una cuenta específica para obtener acceso a recursos o servicios que imponen un límite de conexiones o consiga un mejor rendimiento manteniendo menos conexiones. Este enfoque es común para servicios como bases de datos pero puede afectar a la capacidad de auditar con precisión las operaciones debido a la suplantación del usuario original.
- **Realización de pruebas de generación de perfiles de rendimiento y de carga ** durante el desarrollo, como parte de las rutinas de prueba y antes de la versión final para asegurarse de que la aplicación funciona y escala como corresponde. Estas pruebas deben realizarse en el mismo tipo de hardware que la plataforma de producción y con los mismos tipos y cantidades de datos y de carga de usuarios que se encontrarán en producción. Para obtener más información, consulte la página [Probar el rendimiento de un servicio en la nube](https://msdn.microsoft.com/library/azure/hh369930.aspx) en el sitio web de Microsoft.

<!---HONumber=AcomDC_1223_2015-->